{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4z0JDgisPRr-"
   },
   "source": [
    "# MMClassification tools tutorial on Colab\n",
    "\n",
    "In this tutorial, we will introduce the following content:\n",
    "\n",
    "* How to install MMClassification\n",
    "* Prepare data\n",
    "* Prepare the config file\n",
    "* Train and test model with shell command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inm7Ciy5PXrU"
   },
   "source": [
    "## Install MMClassification\n",
    "\n",
    "Before using MMClassification, we need to prepare the environment with the following steps:\n",
    "\n",
    "1. Install Python, CUDA, C/C++ compiler and git\n",
    "2. Install PyTorch (CUDA version)\n",
    "3. Install mmcv\n",
    "4. Clone mmcls source code from GitHub and install it\n",
    "\n",
    "Because this tutorial is on Google Colab, and the basic environment has been completed, we can skip the first two steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDOxbcDvPbNk"
   },
   "source": [
    "### Check environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4IyFL3MaiYRu",
    "outputId": "193c90c1-a6f0-4b12-d050-14334c2a9f7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storage/Projects/tubetech\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DMw7QwvpiiUO",
    "outputId": "26c019f4-5d08-4dbb-cc69-cca38e25370d"
   },
   "outputs": [],
   "source": [
    "# Check nvcc version\n",
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VIBU7Fain4D",
    "outputId": "03332e7b-b293-488a-be5f-44975cf21bf1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check GCC version\n",
    "!pip install torch, torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24lDLCqFisZ9",
    "outputId": "cda260f3-6f1d-4521-939e-83e221bbefe1"
   },
   "outputs": [],
   "source": [
    "# Check PyTorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDTUrYvXjlRb"
   },
   "source": [
    "### Clone and install MMClassification\n",
    "\n",
    "Now we clone the latest mmcls repository from GitHub and install it by the `mim` tool.\n",
    "\n",
    "> *mim is a light-weight command-line tool to setup appropriate environment for OpenMMLab repositories according to PyTorch and CUDA version. It also has some useful functions for deep-learning experiments.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bwme6tWHjl5s",
    "outputId": "22b43f1e-6fec-4032-f7e9-3b0436c269f3"
   },
   "outputs": [],
   "source": [
    "# Clone mmcls repository and checkout to the 1.x branch\n",
    "!git clone -b 1.x https://github.com/open-mmlab/mmclassification.git\n",
    "%cd mmclassification/\n",
    "\n",
    "# Install MMClassification from source by mim\n",
    "!pip install openmim\n",
    "!mim install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storage/Projects/tubetech/mmclassification\n"
     ]
    }
   ],
   "source": [
    "%cd mmclassification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hFg_oSG4j3zB",
    "outputId": "f68354f7-52a5-43d0-bd95-cec2e08de52f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0rc6\n"
     ]
    }
   ],
   "source": [
    "# Check MMClassification installation\n",
    "import mmcls\n",
    "print(mmcls.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCOHRp3iV5Xk"
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XHCHnKb_Qd3P",
    "outputId": "23a3de3b-3325-429c-bc5c-dbf2067f039a"
   },
   "outputs": [],
   "source": [
    "!curl -L \"https://universe.roboflow.com/ds/7AnNVv41OV?key=Tp2iAqJywA\" > roboflow.zip;\n",
    "!mkdir -p data/rust_dataset\n",
    "!unzip -q roboflow.zip -d ./data/rust_dataset\n",
    "!rm roboflow.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "id": "46tyHTdtQy_Z",
    "outputId": "2810d3df-8b3b-4e17-da86-2fe860982ecb"
   },
   "outputs": [],
   "source": [
    "# Pick an image and visualize it\n",
    "from PIL import Image\n",
    "Image.open('data/rust_dataset/test/Slightly Visible Rust/Steel-145-_jpg.rf.99e877b3d3e2e37dd09a4e1260378e7b.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "My5Z6p7pQ3UC"
   },
   "source": [
    "### Support new dataset\n",
    "\n",
    "We have two methods to support a new dataset in MMClassification.\n",
    "\n",
    "The simplest method is to re-organize the new dataset as the format of a dataset supported officially (like `CustomDataset`). And you can also create a new dataset class. More details are in [the docs](https://mmclassification.readthedocs.io/en/dev-1.x/user_guides/dataset_prepare.html).\n",
    "\n",
    "In this tutorial, for convenience, we have re-organized the cats & dogs dataset as the format of `CustomDataset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P335gKt9Q5U-"
   },
   "source": [
    "Besides image files, it also includes the training/validation/test annotation files. And every line includes an file path and the corresponding label.\n",
    "\n",
    "```\n",
    "...\n",
    "cats/cat.3769.jpg 0\n",
    "cats/cat.882.jpg 0\n",
    "dogs/dog.3881.jpg 1\n",
    "dogs/dog.3377.jpg 1\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BafQ7ijBQ8N_"
   },
   "source": [
    "## Train and test model with shell commands\n",
    "\n",
    "You can use shell commands provided by MMClassification to do the following task:\n",
    "\n",
    "1. Train a model\n",
    "2. Fine-tune a model\n",
    "3. Test a model\n",
    "4. Inference with a model\n",
    "\n",
    "The procedure to train and fine-tune a model is almost the same. And we have introduced how to do these tasks with Python API. In the following, we will introduce how to do them with shell commands. More details are in [the docs](https://mmclassification.readthedocs.io/en/dev-1.x/user_guides/train_test.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aj5cGMihURrZ"
   },
   "source": [
    "### Fine-tune a model\n",
    "\n",
    "The steps to fine-tune a model are as below:\n",
    "\n",
    "1. Prepare the custom dataset.\n",
    "2. Create a new config file of the task.\n",
    "3. Start training task by shell commands.\n",
    "\n",
    "We have finished the first step, and then we will introduce the next two steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBBV3aG79ZH5"
   },
   "source": [
    "#### Create a new config file\n",
    "\n",
    "To reuse the common parts of different config files, we support inheriting multiple base config files. For example, to fine-tune a MobileNetV2 model, the new config file can create the model's basic structure by inheriting `configs/_base_/models/mobilenet_v2_1x.py`.\n",
    "\n",
    "According to the common practice, we usually split whole configs into four parts: model, dataset, learning rate schedule, and runtime. Configs of each part are saved into one file in the `configs/_base_` folder.\n",
    "\n",
    "And then, when creating a new config file, we can select some parts to inherit and only override some different configs.\n",
    "\n",
    "The head of the final config file should look like:\n",
    "\n",
    "```python\n",
    "_base_ = [\n",
    "    '../_base_/models/mobilenet_v2_1x.py',\n",
    "    '../_base_/schedules/imagenet_bs256_epochstep.py',\n",
    "    '../_base_/default_runtime.py'\n",
    "]\n",
    "```\n",
    "\n",
    "Here, because the dataset configs are almost brand new, we don't need to inherit any dataset config file.\n",
    "\n",
    "Of course, you can also create an entire config file without inheritance, like `configs/lenet/lenet5_mnist.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UV3oBhLRG8B"
   },
   "source": [
    "After that, we only need to set the part of configs we want to modify, because the inherited configs will be merged to the final configs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chLX7bL3RP2F"
   },
   "source": [
    "#### Use shell command to start fine-tuning\n",
    "\n",
    "We use `tools/train.py` to fine-tune a model:\n",
    "\n",
    "```shell\n",
    "python tools/train.py ${CONFIG_FILE} [optional arguments]\n",
    "```\n",
    "\n",
    "And if you want to specify another folder to save log files and checkpoints, use the argument `--work_dir ${YOUR_WORK_DIR}`.\n",
    "\n",
    "Here we use the `MobileNetV2` model and cats & dogs dataset as an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3A2N-KoIo3Nd",
    "outputId": "e4f7ed54-714c-4986-81e2-a2a82237b56c"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "emG0pNy1q_Ra"
   },
   "outputs": [],
   "source": [
    "CONFIG = 'configs/deit3/deit3-small-p16_64xb64_in1k-384px_rust.py'\n",
    "MODEL_NAME = 'deit3-small-p16_64xb64_in1k-384px_rust'\n",
    "WORK_DIR = \"/content/gdrive/MyDrive/tubetech_drone_inspection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gbFGR4SBRUYN"
   },
   "outputs": [],
   "source": [
    "!python tools/train.py \\\n",
    "  {CONFIG} \\\n",
    "  --work-dir {WORK_DIR}/{MODEL_NAME}_640"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNW6q1NIpHvK"
   },
   "source": [
    "### save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vWgW_-a0pOFz"
   },
   "outputs": [],
   "source": [
    "!cp \"$(cat work_dirs/{MODEL_NAME}/last_checkpoint)\" /content/gdrive/MyDrive/tubetech_drone_inspection/rust_transformer.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_ZSkwB5Rflb"
   },
   "source": [
    "### Test a model\n",
    "\n",
    "We use `tools/test.py` to test a model:\n",
    "\n",
    "```\n",
    "python tools/test.py ${CONFIG_FILE} ${CHECKPOINT_FILE} [optional arguments]\n",
    "```\n",
    "\n",
    "Here are some optional arguments:\n",
    "\n",
    "- `--out`: Output the metric result to the specified file.\n",
    "- `--dump`: Dump the prediction output of every sample to the specified file.\n",
    "\n",
    "More details are in the help docs of `tools/test.py`.\n",
    "\n",
    "Here we still use the `MobileNetV2` model we fine-tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qawGMBbv6IGB"
   },
   "outputs": [],
   "source": [
    "# weights = !\"$(cat work_dirs/{MODEL_NAME}/last_checkpoint)\"\n",
    "WEIGHTS = '/home/innovation/Projects/tubetech/mmclassification/work_dirs/deit3-large-p16_64xb16_boiler_defects-640px/best_accuracy_top1_epoch_13.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "emG0pNy1q_Ra"
   },
   "outputs": [],
   "source": [
    "CONFIG = 'configs/deit3/deit3-large-p16_64xb16_boiler_defects-640px.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zd4EM00QRtyc",
    "outputId": "68c5ac21-ef99-4b07-9a4e-f4fd2c04fc6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/23 16:50:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 0\n",
      "    GPU 0,1: GeForce GTX 1080 Ti\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 10.2, V10.2.8\n",
      "    GCC: gcc (Ubuntu 6.5.0-2ubuntu1~18.04) 6.5.0 20181026\n",
      "    PyTorch: 2.0.1+cu117\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.7\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
      "  - CuDNN 8.2.4  (built against CUDA 10.2)\n",
      "    - Built with CuDNN 8.5\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2+cu117\n",
      "    OpenCV: 4.7.0\n",
      "    MMEngine: 0.7.4\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 0\n",
      "    deterministic: False\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "06/23 16:50:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "model = dict(\n",
      "    type='ImageClassifier',\n",
      "    backbone=dict(\n",
      "        type='DeiT3',\n",
      "        arch='l',\n",
      "        img_size=640,\n",
      "        patch_size=16,\n",
      "        drop_path_rate=0.4,\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmclassification/v0/deit3/deit3-large-p16_in21k-pre_3rdparty_in1k-384px_20221009-75fea03f.pth',\n",
      "            prefix='backbone')),\n",
      "    neck=None,\n",
      "    head=dict(\n",
      "        type='VisionTransformerClsHead',\n",
      "        num_classes=2,\n",
      "        in_channels=1024,\n",
      "        loss=dict(\n",
      "            type='LabelSmoothLoss', label_smooth_val=0.1, mode='original')),\n",
      "    init_cfg=[\n",
      "        dict(type='TruncNormal', layer='Linear', std=0.02),\n",
      "        dict(type='Constant', layer='LayerNorm', val=1.0, bias=0.0)\n",
      "    ],\n",
      "    train_cfg=dict(augments=[\n",
      "        dict(type='Mixup', alpha=0.8),\n",
      "        dict(type='CutMix', alpha=1.0)\n",
      "    ]))\n",
      "dataset_type = 'CustomDataset'\n",
      "data_preprocessor = dict(num_classes=2)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        scale=640,\n",
      "        backend='pillow',\n",
      "        keep_ratio=True,\n",
      "        interpolation='bicubic'),\n",
      "    dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n",
      "    dict(type='PackClsInputs')\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        scale=640,\n",
      "        backend='pillow',\n",
      "        keep_ratio=True,\n",
      "        interpolation='bicubic'),\n",
      "    dict(type='CenterCrop', crop_size=320),\n",
      "    dict(type='PackClsInputs')\n",
      "]\n",
      "train_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    num_workers=2,\n",
      "    dataset=dict(\n",
      "        type='CustomDataset',\n",
      "        data_prefix='../boiler_defects_dataset2/train',\n",
      "        classes=['clean', 'defect'],\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                scale=640,\n",
      "                backend='pillow',\n",
      "                keep_ratio=True,\n",
      "                interpolation='bicubic'),\n",
      "            dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n",
      "            dict(type='PackClsInputs')\n",
      "        ]),\n",
      "    sampler=dict(type='DefaultSampler', shuffle=True))\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    num_workers=2,\n",
      "    dataset=dict(\n",
      "        type='CustomDataset',\n",
      "        data_prefix='../boiler_defects_dataset2/valid',\n",
      "        classes=['clean', 'defect'],\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                scale=640,\n",
      "                backend='pillow',\n",
      "                keep_ratio=True,\n",
      "                interpolation='bicubic'),\n",
      "            dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n",
      "            dict(type='PackClsInputs')\n",
      "        ]),\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False))\n",
      "test_dataloader = dict(\n",
      "    pin_memory=True,\n",
      "    collate_fn=dict(type='default_collate'),\n",
      "    batch_size=12,\n",
      "    num_workers=4,\n",
      "    dataset=dict(\n",
      "        type='CustomDataset',\n",
      "        data_prefix='../boiler_defects_dataset2/test',\n",
      "        classes=['clean', 'defect'],\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                scale=640,\n",
      "                backend='pillow',\n",
      "                keep_ratio=True,\n",
      "                interpolation='bicubic'),\n",
      "            dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n",
      "            dict(type='PackClsInputs')\n",
      "        ]),\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False))\n",
      "val_evaluator = [\n",
      "    dict(type='Accuracy', topk=1),\n",
      "    dict(\n",
      "        type='MultiLabelMetric',\n",
      "        items=['precision', 'recall', 'f1-score'],\n",
      "        average=None,\n",
      "        thr=0.5)\n",
      "]\n",
      "test_evaluator = [\n",
      "    dict(type='Accuracy', topk=1),\n",
      "    dict(\n",
      "        type='MultiLabelMetric',\n",
      "        items=['precision', 'recall', 'f1-score'],\n",
      "        average=None,\n",
      "        thr=0.5)\n",
      "]\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(type='AdamW', lr=1e-05, weight_decay=0.2),\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict({\n",
      "            '.cls_token': dict(decay_mult=0.0),\n",
      "            '.pos_embed': dict(decay_mult=0.0)\n",
      "        })))\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        type='LinearLR',\n",
      "        start_factor=0.0001,\n",
      "        by_epoch=True,\n",
      "        begin=0,\n",
      "        end=30,\n",
      "        convert_to_iter_based=True),\n",
      "    dict(\n",
      "        type='CosineAnnealingLR', T_max=270, by_epoch=True, begin=30, end=300)\n",
      "]\n",
      "train_cfg = dict(by_epoch=True, max_epochs=15, val_interval=1)\n",
      "val_cfg = dict()\n",
      "test_cfg = dict()\n",
      "auto_scale_lr = dict(base_batch_size=2)\n",
      "default_scope = 'mmcls'\n",
      "default_hooks = dict(\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    logger=dict(type='LoggerHook', interval=1),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    checkpoint=dict(type='CheckpointHook', interval=5, save_best='auto'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    visualization=dict(type='VisualizationHook', enable=True))\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
      "    dist_cfg=dict(backend='nccl'))\n",
      "vis_backends = [dict(type='LocalVisBackend')]\n",
      "visualizer = dict(\n",
      "    type='ClsVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "        dict(type='TensorboardVisBackend'),\n",
      "        dict(\n",
      "            type='WandbVisBackend',\n",
      "            init_kwargs=dict(\n",
      "                project='boiler_defects_classification',\n",
      "                name='deit3-large-p16_64xb16_boiler_defects-640px'))\n",
      "    ])\n",
      "log_level = 'INFO'\n",
      "load_from = '/home/innovation/Projects/tubetech/mmclassification/work_dirs/deit3-large-p16_64xb16_boiler_defects-640px/best_accuracy_top1_epoch_13.pth'\n",
      "resume = False\n",
      "randomness = dict(seed=0, deterministic=False)\n",
      "launcher = 'none'\n",
      "work_dir = './work_dirs/deit3-large-p16_64xb16_boiler_defects-640px'\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33miknowhow\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/storage/Projects/tubetech/mmclassification/work_dirs/deit3-large-p16_64xb16_boiler_defects-640px/20230623_165037/vis_data/wandb/run-20230623_165044-7wh4tk2c\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdeit3-large-p16_64xb16_boiler_defects-640px\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/iknowhow/boiler_defects_classification\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/iknowhow/boiler_defects_classification/runs/7wh4tk2c\u001b[0m\n",
      "06/23 16:50:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Because batch augmentations are enabled, the data preprocessor automatically enables the `to_onehot` option to generate one-hot format labels.\n",
      "06/23 16:50:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "06/23 16:50:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "06/23 16:50:54 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class DumpResults.\n",
      "Loads checkpoint by local backend from path: /home/innovation/Projects/tubetech/mmclassification/work_dirs/deit3-large-p16_64xb16_boiler_defects-640px/best_accuracy_top1_epoch_13.pth\n",
      "06/23 16:50:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /home/innovation/Projects/tubetech/mmclassification/work_dirs/deit3-large-p16_64xb16_boiler_defects-640px/best_accuracy_top1_epoch_13.pth\n",
      "06/23 16:51:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 1/22]    eta: 0:01:25  time: 4.0538  data_time: 0.9298  memory: 2665  \n",
      "06/23 16:51:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 2/22]    eta: 0:01:10  time: 3.5434  data_time: 0.8510  memory: 2665  \n",
      "06/23 16:51:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 3/22]    eta: 0:00:59  time: 3.1154  data_time: 0.5676  memory: 2665  \n",
      "06/23 16:51:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 4/22]    eta: 0:00:52  time: 2.9064  data_time: 0.4260  memory: 2665  \n",
      "06/23 16:51:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 5/22]    eta: 0:00:47  time: 2.8038  data_time: 0.3410  memory: 2665  \n",
      "06/23 16:51:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 6/22]    eta: 0:00:43  time: 2.7311  data_time: 0.2844  memory: 2665  \n",
      "06/23 16:51:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 7/22]    eta: 0:00:39  time: 2.6634  data_time: 0.2439  memory: 2665  \n",
      "06/23 16:51:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 8/22]    eta: 0:00:36  time: 2.6148  data_time: 0.2135  memory: 2665  \n",
      "06/23 16:51:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 9/22]    eta: 0:00:33  time: 2.5757  data_time: 0.1899  memory: 2665  \n",
      "06/23 16:51:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [10/22]    eta: 0:00:30  time: 2.5446  data_time: 0.1710  memory: 2665  \n",
      "06/23 16:51:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [11/22]    eta: 0:00:27  time: 2.3793  data_time: 0.0781  memory: 2665  \n",
      "06/23 16:51:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [12/22]    eta: 0:00:25  time: 2.3183  data_time: 0.0010  memory: 2665  \n",
      "06/23 16:51:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [13/22]    eta: 0:00:22  time: 2.3385  data_time: 0.0010  memory: 2665  \n",
      "06/23 16:51:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [14/22]    eta: 0:00:20  time: 2.3451  data_time: 0.0011  memory: 2665  \n",
      "06/23 16:51:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [15/22]    eta: 0:00:17  time: 2.3325  data_time: 0.0011  memory: 2665  \n",
      "06/23 16:51:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [16/22]    eta: 0:00:14  time: 2.3210  data_time: 0.0010  memory: 2665  \n",
      "06/23 16:51:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [17/22]    eta: 0:00:12  time: 2.3308  data_time: 0.0010  memory: 2665  \n",
      "06/23 16:51:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [18/22]    eta: 0:00:09  time: 2.3348  data_time: 0.0010  memory: 2665  \n",
      "06/23 16:51:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [19/22]    eta: 0:00:07  time: 2.3464  data_time: 0.0010  memory: 2665  \n",
      "06/23 16:51:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [20/22]    eta: 0:00:04  time: 2.3618  data_time: 0.0011  memory: 2665  \n",
      "06/23 16:51:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [21/22]    eta: 0:00:02  time: 2.3627  data_time: 0.0011  memory: 2665  \n",
      "06/23 16:51:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [22/22]    eta: 0:00:00  time: 2.1387  data_time: 0.0011  memory: 1296  \n",
      "06/23 16:51:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Results has been saved to result.pkl.\n",
      "06/23 16:51:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [22/22]    accuracy/top1: 97.2332  multi-label/precision_classwise: [14.285715103149414, 99.59349822998047]  multi-label/recall_classwise: [50.0, 97.60955810546875]  multi-label/f1-score_classwise: [22.22222328186035, 98.59154510498047]  data_time: 0.0783  time: 2.3480\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdeit3-large-p16_64xb16_boiler_defects-640px\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/iknowhow/boiler_defects_classification/runs/7wh4tk2c\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 1 media file(s), 976 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./work_dirs/deit3-large-p16_64xb16_boiler_defects-640px/20230623_165037/vis_data/wandb/run-20230623_165044-7wh4tk2c/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python tools/test.py {CONFIG} {WEIGHTS} --out-item pred --out result.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zebkdLp-1Imw",
    "outputId": "092fa9a8-1a07-40c4-bf0a-0d4545a8bfc9"
   },
   "outputs": [],
   "source": [
    "import mmengine\n",
    "\n",
    "results = mmengine.load(\"result.pkl\")\n",
    "# Output the first samples' ground truth and prediction.\n",
    "print('Ground truth:', results[0]['gt_label'])\n",
    "print('Prediction:', results[0]['pred_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PaVkmoSwZBbl"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%reload_ext tensorboard\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OxYAxsbZY9aI"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir {WORK_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwThQkjaRwF7"
   },
   "source": [
    "### Inference with a model\n",
    "\n",
    "Sometimes we want to save the inference results on a image, just use the command below.\n",
    "\n",
    "```shell\n",
    "python demo/image_demo.py ${IMAGE_FILE} ${CONFIG_FILE} ${CHECKPOINT_FILE}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6GVKloPHR0Fn"
   },
   "outputs": [],
   "source": [
    "!python demo/image_demo.py --checkpoint {WEIGHTS} --show  --show-dir work_dirs/deit3-small-p16_64xb64_in1k-384px_rust/output 'work_dirs/boiler_square.jpg'  configs/deit3/deit3-small-p16_64xb64_in1k-384px_rust.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0nNiRO9TUrYd"
   },
   "outputs": [],
   "source": [
    "!python tools/visualizations/browse_dataset.py configs/mobilenet_v2/mobilenet_v2_1x_rust.py -n 10 -o tmp -m pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gow1lxl9Wvjz"
   },
   "outputs": [],
   "source": [
    "!pip install grad-cam>=1.3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zn4TgzWbWWQW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/23 17:06:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Because batch augmentations are enabled, the data preprocessor automatically enables the `to_onehot` option to generate one-hot format labels.\n",
      "Loads checkpoint by local backend from path: /home/innovation/Projects/tubetech/mmclassification/work_dirs/deit3-large-p16_64xb16_boiler_defects-640px/best_accuracy_top1_epoch_13.pth\n",
      "Automatically choose the last norm layer before the final attention block as target_layer..\n"
     ]
    }
   ],
   "source": [
    "PIC = '/home/innovation/Projects/tubetech/boiler_defects_dataset2/train/defect/2633_L76_jpg.rf.654226d3abb7bdbe260c4d407c270384.jpg'\n",
    "!python tools/visualizations/vis_cam.py \\\n",
    "     {PIC} \\\n",
    "    {CONFIG} \\\n",
    "    {WEIGHTS} \\\n",
    "    --method EigenCAM \\\n",
    "    --save-path layer_activations/boiler_square.jpg \\\n",
    "    --vit-like \\\n",
    "   --num-extra-tokens 21\n",
    "\n",
    "!cp {PIC} 'layer_activations/original.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3JU7DPM0PpRs",
    "outputId": "cb1ed0fe-6121-41b4-a21d-d71f70a0fe88"
   },
   "outputs": [],
   "source": [
    "!pip install fvcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zEL6aS0TPphQ",
    "outputId": "15a2cc6c-1064-421b-d89d-89f9cd5b5cde"
   },
   "outputs": [],
   "source": [
    "!python tools/analysis_tools/get_flops.py {CONFIG} --shape 640"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "My5Z6p7pQ3UC"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
